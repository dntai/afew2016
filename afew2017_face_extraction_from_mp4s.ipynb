{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Zhang - Joint Face Detection and Alignment using Multi-task Cascaded Convolutional Neural Networks\n",
    "# model: https://drive.google.com/open?id=0BxINLo5jshCRUWZsZlJBbmNDdDA\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "# coding: utf-8\n",
    "import mxnet as mx\n",
    "from mtcnn_detector import MtcnnDetector\n",
    "import cv2\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import xml.etree.ElementTree\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\mxnet-0.10.1-py3.5.egg\\mxnet\\model.py:884: DeprecationWarning: \u001b[91mmxnet.model.FeedForward has been deprecated. Please use mxnet.mod.Module instead.\u001b[0m\n",
      "  **kwargs)\n"
     ]
    }
   ],
   "source": [
    "detector = MtcnnDetector(model_folder='model', ctx=mx.gpu(0), num_worker = 4, accurate_landmark = False)\n",
    "\n",
    "save_faces = 1\n",
    "save_aligned_face = 0\n",
    "save_original_faces = 1\n",
    "show_result = 1\n",
    "select_most_frequent_face = 1\n",
    "delete_unfrequent_face = 1\n",
    "\n",
    "t = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_file_title(file_name):\n",
    "    return os.path.splitext(file_name)[0]\n",
    "\n",
    "\n",
    "def cluster_face(x, y, w, h, data, t):\n",
    "    if select_most_frequent_face == 0:\n",
    "        return 0, 0, 0, 0, 0\n",
    "    if len(data) == 0:\n",
    "        min_location = 0\n",
    "        min_size = 0\n",
    "        min_dif = 0\n",
    "        final_g_indx = 0\n",
    "    else:\n",
    "        # for each group\n",
    "        for g_indx in range(0, len(data)):\n",
    "            # calculate absolute different between the last face in each group and\n",
    "            # the current face \n",
    "            # # 1) location\n",
    "            # abs_location = abs(data[g_indx][0][0] - x) + abs(data[g_indx][0][1] - y)\n",
    "            # # 2) size\n",
    "            # abs_size     = abs(data[g_indx][0][2] - w) + abs(data[g_indx][0][3] - h)\n",
    "            # 1) location\n",
    "            abs_location = abs(data[g_indx][len(data[g_indx]) - 1][0] - x) + abs(data[g_indx][len(data[g_indx]) - 1][1] - y)\n",
    "            # 2) size\n",
    "            abs_size = abs(data[g_indx][len(data[g_indx]) - 1][2] - w) + abs(data[g_indx][len(data[g_indx]) - 1][3] - h)\n",
    "            # compare\n",
    "            if g_indx == 0:\n",
    "                min_location = abs_location\n",
    "                min_size = abs_size\n",
    "                min_dif = 1.0*(min_location + min_size)/2\n",
    "                final_g_indx = 0\n",
    "            else:\n",
    "                # if abs_location < min_location and abs_size < min_size:\n",
    "                if 1.0*(abs_location + abs_size)/2 < min_dif:\n",
    "                    min_location = abs_location\n",
    "                    min_size = abs_size\n",
    "                    min_dif = 1.0*(min_location + min_size)/2\n",
    "                    final_g_indx = g_indx\n",
    "    \n",
    "    # decision\n",
    "    # if min_location <= t1 and min_size <= t2:\n",
    "    if min_dif < t:\n",
    "        # print str(final_g_indx) + '_' + str(min_location) + '_' + str(min_size)\n",
    "        return final_g_indx, min_location, min_size, final_g_indx, min_dif\n",
    "    else:\n",
    "        # print str(len(data)) + '_' + str(min_location) + '_' + str(min_size)\n",
    "        return len(data), min_location, min_size, final_g_indx, min_dif\n",
    "\n",
    "\n",
    "def detect_single_face_in_image(img, faces, frm_indx, DIR, file):\n",
    "    # run detector\n",
    "    results = detector.detect_face(img)\n",
    "\n",
    "    draw = img.copy()\n",
    "\n",
    "    if results is not None:\n",
    "        total_boxes = results[0]\n",
    "        points = results[1]\n",
    "\n",
    "        group_indx_for_chips = []\n",
    "        for i, b in enumerate(total_boxes):\n",
    "            # naive face clustering based on location and size\n",
    "            face_indx, location_dif, size_dif, second_face_indx, dif = cluster_face(int(b[0]),\n",
    "                                                                                    int(b[1]), abs(\n",
    "                    int(b[2]) - int(b[0])), abs(int(b[3]) - int(b[1])), faces, t)  # t1, t2)\n",
    "\n",
    "            group_indx_for_chips.append(face_indx)\n",
    "\n",
    "            # add group in case there is another face group\n",
    "            if face_indx + 1 > len(faces):\n",
    "                faces.append([])\n",
    "\n",
    "            # add item in the group\n",
    "            faces[face_indx].append([])\n",
    "\n",
    "            # add x, y, w, and h data\n",
    "            faces[face_indx][len(faces[face_indx]) - 1].append(int(b[0]))\n",
    "            faces[face_indx][len(faces[face_indx]) - 1].append(int(b[1]))\n",
    "            faces[face_indx][len(faces[face_indx]) - 1].append(abs(int(b[2]) - int(b[0])))\n",
    "            faces[face_indx][len(faces[face_indx]) - 1].append(abs(int(b[3]) - int(b[1])))\n",
    "\n",
    "            face = draw[int(b[1]):int(b[3]), int(b[0]):int(b[2])]\n",
    "\n",
    "            if save_faces == 1 and save_original_faces == 1:\n",
    "                cv2.imwrite(DIR + '/' + file + '_unaligned_frame_' + str(frm_indx) + '_g' + str(\n",
    "                    face_indx) + '_sg' + str(second_face_indx) + '_' + str(dif) + '_' + str(\n",
    "                    location_dif) + '_' + str(size_dif) + '_original_face_' + str(i) + '.jpg', face)\n",
    "            cv2.rectangle(draw, (int(b[0]), int(b[1])), (int(b[2]), int(b[3])), (0, 255, 0), 3)\n",
    "            # if save_faces == 1 and save_original_faces == 1:\n",
    "            #     cv2.imwrite(DIR + '/unaligned_frame_' + file, face)\n",
    "            # cv2.rectangle(draw, (int(b[0]), int(b[1])), (int(b[2]), int(b[3])), (0, 255, 0))\n",
    "\n",
    "        # extract aligned face chips\n",
    "        chips = detector.extract_image_chips(img, points, 144, 0.37)\n",
    "        for i, chip in enumerate(chips):\n",
    "            if save_faces == 1 and save_aligned_face == 1:\n",
    "                cv2.imwrite(DIR + '/' + file + '_aligned_frame_' + str(frm_indx) + '_g' + str(\n",
    "                    group_indx_for_chips[i]) + '_sg' + str(second_face_indx) + '_' + str(\n",
    "                    dif) + '_' + str(location_dif) + '_' + str(size_dif) + '_chip_' + str(i) + '.jpg',\n",
    "                            chip)\n",
    "\n",
    "        if show_result == 1:\n",
    "            cv2.imshow(\"detection result\", draw)\n",
    "            # cv2.imwrite('/home/duong/Downloads/EmotiW/AFEW_6_2016/Train/Faces/seminar.17.01.03/' + video_path + '/' + file + '.images/' + file + '_frame_' + str(frm_indx) + '.jpg', draw)\n",
    "            cv2.waitKey(1)\n",
    "\n",
    "    return faces, draw\n",
    "\n",
    "def delete_unfrequent_faces(faces):\n",
    "    # the most frequent face\n",
    "    n_of_faces_per_group = []\n",
    "    for i in range(0, len(faces)):\n",
    "        n_of_faces_per_group.append(len(faces[i]))\n",
    "    print(n_of_faces_per_group)\n",
    "\n",
    "    # best group\n",
    "    for i in range(0, len(faces)):\n",
    "        if len(faces[i]) == max(n_of_faces_per_group):\n",
    "            best_group = i\n",
    "            break\n",
    "    print(best_group)\n",
    "\n",
    "    if delete_unfrequent_face == 1:\n",
    "        # remove unfrequent faces\n",
    "        for exported_file in os.listdir(DIR):\n",
    "            if '_g' + str(best_group) + '_' not in exported_file:\n",
    "                os.remove(DIR + '/' + exported_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    list_of_dirs = ['Angry',\n",
    "                    'Disgust',\n",
    "                    'Fear',\n",
    "                    'Happy',\n",
    "                    'Neutral',\n",
    "                    'Sad',\n",
    "                    'Surprise']\n",
    "    # list_of_dirs = ['Surprise']\n",
    "\n",
    "    dir_indx = 0\n",
    "    for video_path in list_of_dirs:\n",
    "        # PATH = '/mnt/DATA/nhduong/MotionRecognition/data/AFEW/AFEW_6_2016/Train/Data/' + video_path\n",
    "        PATH = 'E:/EmotiW2017/Val_AFEW/' + video_path\n",
    "        vid_indx = 0\n",
    "        for file in os.listdir(PATH):\n",
    "            if file.endswith('.mp4'):\n",
    "                file_name = PATH + '/' + file\n",
    "\n",
    "                DIR = file_name + '.images'\n",
    "                \n",
    "                if save_faces == 1:\n",
    "                    # Create folder to contains faces\n",
    "                    if os.path.exists(DIR):\n",
    "                        shutil.rmtree(DIR)\n",
    "                    os.makedirs(DIR)\n",
    "\n",
    "                # # Create folder to contains faces (seminar)\n",
    "                # if os.path.exists('/home/duong/Downloads/EmotiW/AFEW_6_2016/Train/Faces/seminar.17.01.03/' + video_path + '/' + file + '.images'):\n",
    "                #     shutil.rmtree('/home/duong/Downloads/EmotiW/AFEW_6_2016/Train/Faces/seminar.17.01.03/' + video_path + '/' + file + '.images')\n",
    "                # os.makedirs('/home/duong/Downloads/EmotiW/AFEW_6_2016/Train/Faces/seminar.17.01.03/' + video_path + '/' + file + '.images')\n",
    "\n",
    "                # OpenCV reads video\n",
    "                vid = cv2.VideoCapture(file_name)\n",
    "                \n",
    "                faces = []\n",
    "                \n",
    "                frm_indx = 0\n",
    "                suc = True\n",
    "\n",
    "                while suc:\n",
    "                    suc, img = vid.read()\n",
    "                    \n",
    "                    # Display the frame until new frame is available\n",
    "                    clear_output(wait=True)\n",
    "                    \n",
    "                    print('(' + str(dir_indx + 1) + '/7) processing files in ' + video_path)\n",
    "                    print(' >>> frame %d from %s...' % (frm_indx, file))\n",
    "                    print('')\n",
    "\n",
    "                    # run detector\n",
    "                    results = detector.detect_face(img)\n",
    "\n",
    "                    if results is not None:\n",
    "                        total_boxes = results[0]\n",
    "                        points = results[1]\n",
    "                        # print total_boxes\n",
    "                        # print points\n",
    "                        \n",
    "                        group_indx_for_chips = []\n",
    "                        draw = img.copy()\n",
    "                        for i, b in enumerate(total_boxes):\n",
    "                            # naive face clustering based on location and size\n",
    "                            face_indx, location_dif, size_dif, second_face_indx, dif = cluster_face(int(b[0]), int(b[1]), abs(int(b[2]) - int(b[0])), abs(int(b[3]) - int(b[1])), faces, t)# t1, t2)\n",
    "\n",
    "                            group_indx_for_chips.append(face_indx)\n",
    "                            \n",
    "                            # add group in case there is another face group\n",
    "                            if face_indx + 1 > len(faces):\n",
    "                                faces.append([])\n",
    "                            \n",
    "                            # add item in the group\n",
    "                            faces[face_indx].append([])\n",
    "                            \n",
    "                            # add x, y, w, and h data\n",
    "                            faces[face_indx][len(faces[face_indx]) - 1].append(int(b[0]))\n",
    "                            faces[face_indx][len(faces[face_indx]) - 1].append(int(b[1]))\n",
    "                            faces[face_indx][len(faces[face_indx]) - 1].append(abs(int(b[2]) - int(b[0])))\n",
    "                            faces[face_indx][len(faces[face_indx]) - 1].append(abs(int(b[3]) - int(b[1])))\n",
    "                            \n",
    "                            face = draw[int(b[1]):int(b[3]), int(b[0]):int(b[2])]\n",
    "                            if save_faces == 1 and save_original_faces == 1:\n",
    "                                cv2.imwrite(DIR + '/' + file + '_unaligned_frame_'+str(frm_indx)+'_g'+str(face_indx)+'_sg'+str(second_face_indx)+'_'+str(dif)+'_'+str(location_dif)+'_'+str(size_dif)+'_original_face_'+str(i)+'.jpg', face)\n",
    "                            cv2.rectangle(draw, (int(b[0]), int(b[1])), (int(b[2]), int(b[3])), (0, 255, 0), 3)\n",
    "                        \n",
    "                        # extract aligned face chips\n",
    "                        chips = detector.extract_image_chips(img, points, 144, 0.37)\n",
    "                        for i, chip in enumerate(chips):\n",
    "                            if save_faces == 1 and save_aligned_face == 1:\n",
    "                                cv2.imwrite(DIR + '/' + file + '_aligned_frame_'+str(frm_indx)+'_g'+str(group_indx_for_chips[i])+'_sg'+str(second_face_indx)+'_'+str(dif)+'_'+str(location_dif)+'_'+str(size_dif)+'_chip_'+str(i)+'.jpg', chip)\n",
    "\n",
    "                        # for p in points:\n",
    "                        #     for i in range(5):\n",
    "                        #         cv2.circle(draw, (p[i], p[i + 5]), 1, (0, 0, 255), 2)\n",
    "\n",
    "                        if show_result == 1:\n",
    "                            cv2.imshow(\"detection result\", draw)\n",
    "                            # cv2.imwrite('/home/duong/Downloads/EmotiW/AFEW_6_2016/Train/Faces/seminar.17.01.03/' + video_path + '/' + file + '.images/' + file + '_frame_' + str(frm_indx) + '.jpg', draw)\n",
    "                            k = cv2.waitKey(1)\n",
    "                            if k == 27:\n",
    "                                cv2.destroyAllWindows()\n",
    "                                sys.exit(0)\n",
    "                            \n",
    "#                             # Turn off the axis\n",
    "#                             plt.axis('off')\n",
    "#                             # Display the frame\n",
    "#                             plt.suptitle('face detection')\n",
    "#                             plt.imshow(draw)\n",
    "#                             plt.show()\n",
    "\n",
    "                    frm_indx += 1\n",
    "                    \n",
    "                # the most frequent face\n",
    "                n_of_faces_per_group = []\n",
    "                for i in range(0, len(faces)):\n",
    "                    n_of_faces_per_group.append(len(faces[i]))\n",
    "                print(n_of_faces_per_group)\n",
    "                \n",
    "                # best group\n",
    "                for i in range(0, len(faces)):\n",
    "                    if len(faces[i]) == max(n_of_faces_per_group):\n",
    "                        best_group = i\n",
    "                        break                \n",
    "                print(best_group)\n",
    "                \n",
    "                if delete_unfrequent_face == 1:\n",
    "                    # remove unfrequent faces\n",
    "                    for exported_file in os.listdir(DIR):\n",
    "                        if '_g' + str(best_group) + '_' not in exported_file:\n",
    "                            os.remove(DIR + '/' + exported_file)\n",
    "                \n",
    "                vid_indx += 1\n",
    "            \n",
    "#            if vid_indx > 0:\n",
    "#                break\n",
    "#        break                    \n",
    "        dir_indx += 1\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7/7) processing files in Surprise\n",
      " >>> frame 53 from 015646720.avi.mp4...\n",
      "\n",
      "[53]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    multiprocessing.freeze_support()\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
