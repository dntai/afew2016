{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.keras.python.keras import applications, layers\n",
    "from tensorflow.contrib.keras.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.contrib.keras.python.keras import optimizers\n",
    "from tensorflow.contrib.keras.python.keras.models import Sequential, Model\n",
    "from tensorflow.contrib.keras.python.keras.layers import Dropout, Flatten, Dense, Input, ZeroPadding2D, Conv2D, BatchNormalization, Activation, MaxPooling2D, AveragePooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.contrib.keras.python.keras.callbacks import EarlyStopping\n",
    "from tensorflow.contrib.keras.python.keras.optimizers import Adam\n",
    "\n",
    "# from tensorflow.contrib.keras.python.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.contrib.keras.python.keras.applications.imagenet_utils import _obtain_input_shape\n",
    "from tensorflow.contrib.keras.python.keras import backend as K\n",
    "\n",
    "from residual_funcs import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the base model ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine proper input shape\n",
    "input_shape = _obtain_input_shape(None,\n",
    "                                default_size=224,\n",
    "                                min_size=197,\n",
    "                                data_format=K.image_data_format(),\n",
    "                                include_top=False)\n",
    "\n",
    "img_input = Input(shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_axis = 3\n",
    "\n",
    "x = ZeroPadding2D((3, 3))(img_input)\n",
    "x = Conv2D(64, (7, 7), strides=(2, 2), name='conv1')(x)\n",
    "x = BatchNormalization(axis=bn_axis, name='bn_conv1')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n",
    "x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n",
    "x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n",
    "\n",
    "x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\n",
    "x = identity_block(x, 3, [128, 128, 512], stage=3, block='b')\n",
    "x = identity_block(x, 3, [128, 128, 512], stage=3, block='c')\n",
    "x = identity_block(x, 3, [128, 128, 512], stage=3, block='d')\n",
    "\n",
    "x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')\n",
    "x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b')\n",
    "x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c')\n",
    "x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d')\n",
    "x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e')\n",
    "x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f')\n",
    "\n",
    "x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')\n",
    "x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n",
    "x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n",
    "\n",
    "x = AveragePooling2D((7, 7), name='avg_pool')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = img_input\n",
    "\n",
    "# Create model.\n",
    "base_model = Model(inputs, x, name='resnet50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained model\n",
    "base_model.load_weights('resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FC layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add 2 fully-connected layers\n",
    "x = Dense(2048, activation='relu')(x)\n",
    "x = Dropout(0.25)(x)\n",
    "x = Dense(2048, activation='relu')(x)\n",
    "x = Dropout(0.25)(x)\n",
    "# and a logistic layer -- let's say we have 2 classes\n",
    "predictions = Dense(5, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional ResNet50 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "opt = Adam(lr=0.0001, decay=10e-6)\n",
    "model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2720 images belonging to 5 classes.\n",
      "Found 950 images belonging to 5 classes.\n",
      "Epoch 1/100\n",
      "20/20 [==============================] - 32s - loss: 0.8329 - acc: 0.6902 - val_loss: 0.7020 - val_acc: 0.7263\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 28s - loss: 0.3563 - acc: 0.8813 - val_loss: 0.5293 - val_acc: 0.8063\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 28s - loss: 0.2664 - acc: 0.9077 - val_loss: 0.4990 - val_acc: 0.8221\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 28s - loss: 0.1972 - acc: 0.9371 - val_loss: 0.3957 - val_acc: 0.8568\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 28s - loss: 0.1227 - acc: 0.9660 - val_loss: 0.3471 - val_acc: 0.8663\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 28s - loss: 0.1182 - acc: 0.9633 - val_loss: 0.3566 - val_acc: 0.8758\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 28s - loss: 0.0961 - acc: 0.9755 - val_loss: 0.2959 - val_acc: 0.8937\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 28s - loss: 0.0897 - acc: 0.9703 - val_loss: 0.3026 - val_acc: 0.8905\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 28s - loss: 0.0721 - acc: 0.9817 - val_loss: 0.3223 - val_acc: 0.8905\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 28s - loss: 0.0444 - acc: 0.9910 - val_loss: 0.3135 - val_acc: 0.8905\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 28s - loss: 0.0366 - acc: 0.9918 - val_loss: 0.2966 - val_acc: 0.9032\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 28s - loss: 0.0312 - acc: 0.9926 - val_loss: 0.2952 - val_acc: 0.9032\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 28s - loss: 0.0226 - acc: 0.9980 - val_loss: 0.3460 - val_acc: 0.8895\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 28s - loss: 0.0242 - acc: 0.9954 - val_loss: 0.3241 - val_acc: 0.9021\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 28s - loss: 0.0164 - acc: 0.9973 - val_loss: 0.3263 - val_acc: 0.9032\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 28s - loss: 0.0134 - acc: 0.9988 - val_loss: 0.3435 - val_acc: 0.8947\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 28s - loss: 0.0130 - acc: 0.9973 - val_loss: 0.3429 - val_acc: 0.9053\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 28s - loss: 0.0137 - acc: 0.9977 - val_loss: 0.3496 - val_acc: 0.9011\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.contrib.keras.python.keras.callbacks.History at 0x21ee71395f8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "train_datagen = ImageDataGenerator()\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "     \"./data/train\",\n",
    "    target_size=(224, 244),\n",
    "    batch_size=128,\n",
    "    class_mode='binary')\n",
    "\n",
    "val_datagen = ImageDataGenerator()\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "     \"./data/val\",\n",
    "    target_size=(224, 244),\n",
    "    batch_size=95,\n",
    "    class_mode='binary')\n",
    "\n",
    "model.fit_generator(generator=train_generator, steps_per_epoch=20,\n",
    "                    epochs=100, verbose=1, callbacks=[early_stopping],\n",
    "                    validation_data=val_generator, validation_steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
