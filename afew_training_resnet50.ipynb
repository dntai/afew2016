{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.keras.python.keras import applications, layers\n",
    "from tensorflow.contrib.keras.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.contrib.keras.python.keras import optimizers\n",
    "from tensorflow.contrib.keras.python.keras.models import Sequential, Model\n",
    "from tensorflow.contrib.keras.python.keras.layers import Dropout, Flatten, Dense, Input, ZeroPadding2D, Conv2D, BatchNormalization, Activation, MaxPooling2D, AveragePooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.contrib.keras.python.keras.callbacks import EarlyStopping\n",
    "from tensorflow.contrib.keras.python.keras.optimizers import Adam\n",
    "\n",
    "# from tensorflow.contrib.keras.python.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.contrib.keras.python.keras.applications.imagenet_utils import _obtain_input_shape\n",
    "from tensorflow.contrib.keras.python.keras import backend as K\n",
    "\n",
    "from residual_funcs import *\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_emotion(ohv):\n",
    "    if ohv.shape[0] == 1:\n",
    "        indx = ohv[0]\n",
    "    else:\n",
    "        indx = np.argmax(ohv)\n",
    "        \n",
    "    if indx == 0:\n",
    "        return 'angry'\n",
    "    elif indx == 1:\n",
    "        return 'disgust'\n",
    "    elif indx == 2:\n",
    "        return 'fear'\n",
    "    elif indx == 3:\n",
    "        return 'happy'\n",
    "    elif indx == 4:\n",
    "        return 'sad'\n",
    "    elif indx == 5:\n",
    "        return 'surprise'\n",
    "    elif indx == 6:\n",
    "        return 'neutral'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the base model ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Determine proper input shape\n",
    "input_shape = _obtain_input_shape(None,\n",
    "                                default_size=224,\n",
    "                                min_size=197,\n",
    "                                data_format=K.image_data_format(),\n",
    "                                include_top=False)\n",
    "\n",
    "img_input = Input(shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_axis = 3\n",
    "\n",
    "x = ZeroPadding2D((3, 3))(img_input)\n",
    "x = Conv2D(64, (7, 7), strides=(2, 2), name='conv1')(x)\n",
    "x = BatchNormalization(axis=bn_axis, name='bn_conv1')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n",
    "x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n",
    "x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n",
    "\n",
    "x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\n",
    "x = identity_block(x, 3, [128, 128, 512], stage=3, block='b')\n",
    "x = identity_block(x, 3, [128, 128, 512], stage=3, block='c')\n",
    "x = identity_block(x, 3, [128, 128, 512], stage=3, block='d')\n",
    "\n",
    "x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')\n",
    "x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b')\n",
    "x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c')\n",
    "x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d')\n",
    "x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e')\n",
    "x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f')\n",
    "\n",
    "x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')\n",
    "x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n",
    "x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n",
    "\n",
    "x = AveragePooling2D((7, 7), name='avg_pool')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = img_input\n",
    "\n",
    "# Create model.\n",
    "base_model = Model(inputs, x, name='resnet50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load trained model\n",
    "base_model.load_weights('resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# FC layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add 2 fully-connected layers\n",
    "x = Dense(1204, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "# and a logistic layer -- let's say we have 2 classes\n",
    "predictions = Dense(7, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional ResNet50 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "opt = Adam(lr=0.0001, decay=10e-6)\n",
    "model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 41225 images belonging to 7 classes.\n",
      "Found 19871 images belonging to 7 classes.\n",
      "Epoch 1/200\n",
      "323/323 [==============================] - 759s - loss: 0.8181 - acc: 0.7378 - val_loss: 2.0901 - val_acc: 0.2886\n",
      "Epoch 2/200\n",
      "263/323 [=======================>......] - ETA: 46s - loss: 0.5896 - acc: 0.8270"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "# fer2013 ------------------------------------------------\n",
    "# train_datagen = ImageDataGenerator()\n",
    "# train_generator = train_datagen.flow_from_directory(\n",
    "#      \"./data/fer2013/train\",\n",
    "#     target_size=(224, 244),\n",
    "#     batch_size=128,\n",
    "#     class_mode='binary')\n",
    "\n",
    "# val_datagen = ImageDataGenerator()\n",
    "# val_generator = val_datagen.flow_from_directory(\n",
    "#      \"./data/fer2013/test1\",\n",
    "#     target_size=(224, 244),\n",
    "#     batch_size=1,\n",
    "#     class_mode='binary')\n",
    "\n",
    "# afew2017 ------------------------------------------------\n",
    "train_datagen = ImageDataGenerator()\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "     \"E:/EmotiW2017/Train_AFEW/face_images\",\n",
    "    target_size=(224, 244),\n",
    "    batch_size=128,\n",
    "    class_mode='binary')\n",
    "\n",
    "val_datagen = ImageDataGenerator()\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "     \"E:/EmotiW2017/Val_AFEW/face_images\",\n",
    "    target_size=(224, 244),\n",
    "    batch_size=1,\n",
    "    class_mode='binary')\n",
    "\n",
    "model.fit_generator(generator=train_generator, steps_per_epoch=323,\n",
    "                    epochs=200, verbose=1, callbacks=[early_stopping],\n",
    "                    validation_data=val_generator, validation_steps=19871)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's visualize layer names and layer indices to see how many layers\n",
    "# we should freeze:\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "   print(i, layer.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scores = model.evaluate(x_testing, y_testing)\n",
    "# print('%s: %.2f%%'% (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model.save('fer2013.h5')\n",
    "model.save_weights('emotiw2017_mxnet_cascade_cnn_face_resnet50_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model.load_weights('fer2013_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scores = model.evaluate(x_testing, y_testing)\n",
    "# print('%s: %.2f%%'% (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Test trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # 2163\n",
    "# img_indx = np.uint32(np.random.rand()*(testingset.shape[0] - 1))\n",
    "# sample = x_testing[img_indx, :]\n",
    "# sample = sample.reshape(48, 48)\n",
    "\n",
    "# pred_cls = model.predict_classes(sample.reshape(1, 48, 48, 1))\n",
    "\n",
    "# plt.imshow(sample, cmap='gray')\n",
    "# plt.show()\n",
    "# print('> testing image index: %d\\n> true emotion: %s\\n> predicted emotion: %s' % (img_indx, get_emotion(y_testing[img_indx, :]), get_emotion(pred_cls)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Partial accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for emo_indx in range(0, n_classes):\n",
    "#     data_for_class = testingset[testingset[:, 2304 + emo_indx] == 1]\n",
    "#     x_data = data_for_class[:, 0:2304]\n",
    "#     x_data = x_data.reshape(x_data.shape[0], 48, 48)\n",
    "#     x_data = np.expand_dims(x_data, axis=4)\n",
    "\n",
    "#     y_data = data_for_class[:, 2304:2304 + n_classes]\n",
    "\n",
    "#     scores = model.evaluate(x_data, y_data, batch_size=32, verbose=0)\n",
    "#     print('> Accuracy %.2f%% for <%s>'% (scores[1]*100, get_emotion(np.array([emo_indx]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
